{
    "name": "/mnt/task_runtime/dcnlp/eval/heavy",
    "uuid": "8eb21722-0c19-4431-99d2-f370418b81b4",
    "model": "open_lm_1b_swiglutorch",
    "creation_date": "2024_06_04-08_46_35",
    "eval_metrics": {
        "icl": {
            "mmlu_zeroshot": 0.25394152392420855,
            "hellaswag_zeroshot": 0.5554670095443726,
            "jeopardy": 0.20884807407855988,
            "triviaqa_sm_sub": 0.15600000321865082,
            "gsm8k_cot": 0.008339650928974152,
            "agi_eval_sat_math_cot": 0.013636363670229912,
            "aqua_cot": 0.01224489789456129,
            "svamp_cot": 0.0533333346247673,
            "bigbench_qa_wikidata": 0.5767924785614014,
            "arc_easy": 0.630892276763916,
            "arc_challenge": 0.3395904302597046,
            "mmlu_fewshot": 0.24019598176604823,
            "bigbench_misconceptions": 0.47031962871551514,
            "copa": 0.6800000071525574,
            "siqa": 0.501023530960083,
            "commonsense_qa": 0.19656018912792206,
            "piqa": 0.7241566777229309,
            "openbook_qa": 0.3779999911785126,
            "bigbench_novel_concepts": 0.4375,
            "bigbench_strange_stories": 0.5517241358757019,
            "bigbench_strategy_qa": 0.5377894043922424,
            "lambada_openai": 0.5755870342254639,
            "hellaswag": 0.5562636852264404,
            "winograd": 0.761904776096344,
            "winogrande": 0.5864246487617493,
            "bigbench_conlang_translation": 0.018292682245373726,
            "bigbench_language_identification": 0.25279998779296875,
            "bigbench_conceptual_combinations": 0.3106796145439148,
            "bigbench_elementary_math_qa": 0.24234801530838013,
            "bigbench_dyck_languages": 0.25200000405311584,
            "agi_eval_lsat_ar": 0.2130434811115265,
            "bigbench_cs_algorithms": 0.41439393162727356,
            "bigbench_logical_deduction": 0.25600001215934753,
            "bigbench_operators": 0.17142857611179352,
            "bigbench_repeat_copy_logic": 0.03125,
            "simple_arithmetic_nospaces": 0.0010000000474974513,
            "simple_arithmetic_withspaces": 0.006000000052154064,
            "math_qa": 0.2598055601119995,
            "logi_qa": 0.24731183052062988,
            "pubmed_qa_labeled": 0.2150000035762787,
            "squad": 0.3332071900367737,
            "agi_eval_lsat_rc": 0.23880596458911896,
            "agi_eval_lsat_lr": 0.26862746477127075,
            "coqa": 0.2705749571323395,
            "bigbench_understanding_fables": 0.21693122386932373,
            "boolq": 0.5498470664024353,
            "agi_eval_sat_en": 0.2572815418243408,
            "winogender_mc_female": 0.5666666626930237,
            "winogender_mc_male": 0.46666666865348816,
            "enterprise_pii_classification": 0.5187039971351624,
            "bbq": 0.4424171041358601,
            "gpqa_main": 0.21875,
            "gpqa_diamond": 0.2222222238779068
        }
    },
    "missing tasks": "[]",
    "aggregated_task_categories_centered": {
        "commonsense reasoning": 0.2128114604213364,
        "language understanding": 0.2956354289530286,
        "reading comprehension": 0.09991671332043775,
        "safety": -0.0027727836912328496,
        "symbolic problem solving": 0.0764362273770746,
        "world knowledge": 0.14230697287453548
    },
    "aggregated_centered_results": 0.1401024684187729,
    "aggregated_results": 0.32959606601988967,
    "rw_small": 0.5570369064807892,
    "rw_small_centered": 0.23047265846129747,
    "95%_CI_above": 0.41841551569568647,
    "95%_CI_above_centered": 0.22641380038031014,
    "99%_CI_above": 0.4234754993863728,
    "99%_CI_above_centered": 0.2622813880471989,
    "low_variance_datasets": 0.42086511240764096,
    "low_variance_datasets_centered": 0.2708209869813578,
    "model_uuid": "96a00026-2a36-416f-9df8-ac4e66d02f19",
    "_filename": "exp_data/evals/evaluation_rw_v2_cc_v3_f0.15_resiliparse_fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_0.1-open_lm_1b_swiglutorch-warm=5000-lr=0p003-wd=0p33-cd=3e-05-bs=256-mult=1-seed=124-tokens=28795904000_heavy.json",
    "Core": 0.2708209869813578,
    "Extended": 0.1401024684187729
}