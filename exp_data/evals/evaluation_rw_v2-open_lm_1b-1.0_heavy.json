{
    "name": "/mnt/task_runtime/dcnlp/eval/heavy",
    "uuid": "69baa06d-15f2-4303-a1e1-1a993b1ec8b0",
    "model": "open_lm_1b",
    "creation_date": "2024_01_26-11_21_58",
    "eval_metrics": {
        "icl": {
            "mmlu_zeroshot": 0.25987648284226134,
            "hellaswag_zeroshot": 0.5705038905143738,
            "jeopardy": 0.1719512939453125,
            "triviaqa_sm_sub": 0.00033333332976326346,
            "gsm8k": 0.0,
            "agi_eval_sat_math": 0.004545454401522875,
            "aqua": 0.0,
            "bigbench_qa_wikidata": 0.6051867604255676,
            "arc_easy": 0.5951178669929504,
            "arc_challenge": 0.29436859488487244,
            "bigbench_misconceptions": 0.45205479860305786,
            "copa": 0.7400000095367432,
            "siqa": 0.4984646737575531,
            "commonsense_qa": 0.2153972089290619,
            "piqa": 0.7334058880805969,
            "openbook_qa": 0.35600000619888306,
            "bigbench_novel_concepts": 0.4375,
            "bigbench_strange_stories": 0.5344827771186829,
            "bigbench_strategy_qa": 0.5133246183395386,
            "lambada_openai": 0.5542402267456055,
            "hellaswag": 0.5720971822738647,
            "winograd": 0.761904776096344,
            "winogrande": 0.5714285969734192,
            "bigbench_conlang_translation": 0.018292682245373726,
            "bigbench_language_identification": 0.2623000144958496,
            "bigbench_conceptual_combinations": 0.21359223127365112,
            "bigbench_elementary_math_qa": 0.24350105226039886,
            "bigbench_dyck_languages": 0.16200000047683716,
            "agi_eval_lsat_ar": 0.30000001192092896,
            "bigbench_cs_algorithms": 0.42500001192092896,
            "bigbench_logical_deduction": 0.23533333837985992,
            "bigbench_operators": 0.16190476715564728,
            "bigbench_repeat_copy_logic": 0.03125,
            "simple_arithmetic_nospaces": 0.0020000000949949026,
            "simple_arithmetic_withspaces": 0.004000000189989805,
            "math_qa": 0.24472008645534515,
            "logi_qa": 0.2611367106437683,
            "pubmed_qa_labeled": 0.5230000019073486,
            "squad": 0.33746451139450073,
            "agi_eval_lsat_rc": 0.302238792181015,
            "agi_eval_lsat_lr": 0.24313725531101227,
            "coqa": 0.27846673130989075,
            "bigbench_understanding_fables": 0.2539682686328888,
            "boolq": 0.5908256769180298,
            "agi_eval_sat_en": 0.223300963640213,
            "winogender_mc_female": 0.5666666626930237,
            "winogender_mc_male": 0.46666666865348816,
            "enterprise_pii_classification": 0.4848306477069855,
            "bbq": 0.47589324008334766,
            "mmlu_fewshot": 0.25025247717112825,
            "gsm8k_cot": 0.007581501267850399,
            "agi_eval_sat_math_cot": 0.013636363670229912,
            "aqua_cot": 0.016326529905200005,
            "svamp_cot": 0.036666665226221085,
            "gpqa_main": 0.2254464328289032,
            "gpqa_diamond": 0.24242424964904785
        }
    },
    "model_uuid": "a9834bae-9040-4bbf-89bd-dc288500eb58",
    "aggregated_task_categories_centered": {
        "commonsense reasoning": 0.13955584301970514,
        "language understanding": 0.24233227080563594,
        "reading comprehension": 0.136543802067376,
        "safety": -0.002971390431577514,
        "symbolic problem solving": 0.06463738437224593,
        "world knowledge": 0.11715624573989772
    },
    "aggregated_centered_results": 0.11842816959241682,
    "aggregated_results": 0.3309710100613651,
    "rw_small": 0.5603741059700648,
    "95%_CI_above": 0.42634969509460713,
    "99%_CI_above": 0.43636281140472577,
    "low_variance_datasets": 0.42230972850864584,
    "_filename": "exp_data/evals/evaluation_rw_v2-open_lm_1b-1.0_heavy.json",
    "missing tasks": "[]",
    "rw_small_centered": 0.24878941363061383,
    "95%_CI_above_centered": 0.217723054984199,
    "99%_CI_above_centered": 0.2620306005906222,
    "low_variance_datasets_centered": 0.25229284252685413,
    "Core": 0.25229284252685413,
    "Extended": 0.11842816959241682,
    "Core_v1": 0.27792335235012994,
    "Extended_v1": 0.14239515872734176,
    "Core_v2": 0.25229284252685413,
    "Extended_v2": 0.11842816959241682,
    "eval_version": "v2"
}